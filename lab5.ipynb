{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5 - metryki w przestrzeni napisów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zadanie dotyczy różnych metryk w przestrzeni napisów.\n",
    "\n",
    "1. Zaimplementuj przynajmniej 3 metryki spośród wymienionych: cosinusowa, LCS, DICE, euklidesowa.\n",
    "2. Zaimplementuj przynajmniej 2 sposoby oceny jakości klasteryzacji (np. indeks Daviesa-Bouldina).\n",
    "3. Stwórz stoplistę najczęściej występujących słów.\n",
    "4. Wykonaj klasteryzację zawartości załączonego pliku (lines.txt) przy użyciu przynajmniej 2 algorytmów oraz metryk zaimplementowanych w pkt. 1. i metryki Levenshteina. Każda linia to adres pocztowy firmy, różne sposoby zapisu tego samego adresu powinny się znaleźć w jednym klastrze.\n",
    "5. Porównaj jakość wyników sposobami zaimplementowanymi w pkt. 2.\n",
    "6. Czy masz jakiś pomysł na poprawę jakości klasteryzacji w tym zadaniu?\n",
    "\n",
    "Sprawozdanie powinno zawierać porównanie wyników wszystkich metryk z użyciem stoplisty i bez.\n",
    "Można jako wzorcową klasteryzację użyć pliku clusters.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-gramy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_gram_dict(text, n, d = {}):\n",
    "    l = len(text)\n",
    "\n",
    "    for j in range(l-n+1):\n",
    "        t = text[j:j+n]\n",
    "        if t in d.keys():\n",
    "            d[t] += 1\n",
    "        else:\n",
    "            d[t] = 1\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tex': 2, 'ext': 2, 'xtt': 1, 'tte': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gram_dict(\"texttext\", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metryki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metryka LCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LCS(text1, text2):\n",
    "    n = len(text1)\n",
    "    m = len(text2)\n",
    "    \n",
    "    dp = [[0]*(m+1) for _ in range(n+1)]\n",
    "    result = 0\n",
    "    for i in range(1, n+1):\n",
    "        for j in range(1, m+1):\n",
    "            if text1[i-1] == text2[j-1]:\n",
    "                dp[i][j] = dp[i-1][j-1] + 1\n",
    "                result = max(result, dp[i][j])\n",
    "            else:\n",
    "                dp[i][j] = 0\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LCS_metric(text1, text2):\n",
    "    if len(text1)==0 and len(text2)==0:\n",
    "        return 0\n",
    "    return 1 - LCS(text1, text2)/max(len(text1), len(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LCS_matrix(text):\n",
    "    n = len(text)\n",
    "    matrix = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            matrix[i][j] = matrix[j][i] = LCS_metric(text[i], text[j])\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6363636363636364"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LCS_metric(\"texttextttttttttttttt\", \"errrrrrrtexttextaaaaaa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matryka cosinusowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_metric(vec1, vec2):\n",
    "    s = 0\n",
    "    t1_s = 0\n",
    "    t2_s = 0\n",
    "    for i in range(len(vec1)):\n",
    "        s += vec1[i]*vec2[i]\n",
    "        t1_s += vec1[i]**2\n",
    "        t2_s += vec2[i]**2\n",
    "    if t1_s != 0 and t2_s != 0:\n",
    "        return 1 - s/(np.sqrt(t1_s) * np.sqrt(t2_s))\n",
    "    else:\n",
    "        return 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_metric_2(text1, text2, n=3):\n",
    "    t1_dict = n_gram_dict(text1, n, {})\n",
    "    t2_dict = n_gram_dict(text2, n, {})\n",
    "    \n",
    "    s = 0\n",
    "    t1_s = 0\n",
    "    t2_s = 0\n",
    "    for key in t1_dict.keys():\n",
    "        if key in t2_dict.keys():\n",
    "            s += t1_dict[key] * t2_dict[key]\n",
    "    \n",
    "    for key in t1_dict.keys():\n",
    "        t1_s += t1_dict[key]**2\n",
    "        \n",
    "    for key in t2_dict.keys():\n",
    "        t2_s += t2_dict[key]**2\n",
    "    \n",
    "    return 1 - s/(np.sqrt(t1_s) * np.sqrt(t2_s))        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8826862694567411"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_metric_2(\"texttextttttttttttttt\", \"errrrrrrtexttextaaaaaa\", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metryka euklidesowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_metric(vec1, vec2):\n",
    "    s = 0\n",
    "    for i in range(len(vec1)):\n",
    "        s += (vec1[i] - vec2[i])**2\n",
    "    \n",
    "    return np.sqrt(s)\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_metric_2(text1, text2, n=3):\n",
    "    t1_dict = n_gram_dict(text1, n)\n",
    "    t2_dict = n_gram_dict(text2, n)\n",
    "    \n",
    "    s = 0\n",
    "    for key in t1_dict.keys():\n",
    "        if key in t2_dict.keys():\n",
    "            s += (t1_dict[key] - t2_dict[key])**2\n",
    "        else:\n",
    "            s += t1_dict[key]**2\n",
    "            \n",
    "    for key in t2_dict.keys():\n",
    "        if key not in t1_dict.keys():\n",
    "            s += t2_dict[key]**2\n",
    "    return np.sqrt(s)\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metryka Dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_metric(vec1, vec2):\n",
    "    s = 0\n",
    "    for i in range(len(vec1)):\n",
    "        s += min(vec1[i], vec2[i])\n",
    "        \n",
    "    if np.sum(vec1) + np.sum(vec2) == 0.0:\n",
    "        return 0\n",
    "    return 1 - 2*s/(np.sum(vec1)+np.sum(vec2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Odległość Levenshteina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Levenshtein_distance(text1, text2):\n",
    "    n = len(text1)\n",
    "    m = len(text2)  \n",
    "    dp = [[0]*(n+1) for _ in range(m+1)]\n",
    "    for i in range(n+1):\n",
    "        dp[0][i]=i\n",
    "    for i in range(m+1):\n",
    "        dp[i][0] = i\n",
    "    \n",
    "    for i in range(1,m+1):\n",
    "        for j in range(1,n+1):\n",
    "            if text1[j-1] != text2[i-1]:\n",
    "                insert = dp[i][j-1] + 1\n",
    "                remove = dp[i-1][j] + 1\n",
    "                replace = dp[i-1][j-1] + 1\n",
    "                dp[i][j] = min(insert, remove, replace)\n",
    "            else:\n",
    "                dp[i][j] = dp[i-1][j-1]\n",
    "    \n",
    "    return dp[m][n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Levenshtein_matrix_dist(text):\n",
    "    n = len(text)\n",
    "    matrix = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            matrix[i][j] = matrix[j][i] = Levenshtein_distance(text[i], text[j])\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ocena jakości klasteryzacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zwraca średnią odległość pomiędzy losowymi elementami z obu klastrów \"i\" oraz \"j\"\n",
    "def clusters_dist(clusters, i, j, metric_function = euclidean_metric):\n",
    "    d = metric_function(clusters[i][0], clusters[j][0])\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def element_dist(cluster, metric_function = euclidean_metric):\n",
    "    dist = 0\n",
    "    i = 0\n",
    "    n = len(cluster)\n",
    "    for j in range(n):\n",
    "        for k in range(j+1, n):\n",
    "            dist += metric_function(cluster[j], cluster[k])\n",
    "            i +=1\n",
    "    if i==0:\n",
    "        return 0 # tylko 1 element w klastrze\n",
    "    return dist/i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indeks Daviesa-Bouldina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DBI(clusters, metric_function = euclidean_metric):\n",
    "    n = len(clusters) #liczba klastrów\n",
    "    average_element_dist = [0]*n\n",
    "    for i in range(n):\n",
    "        average_element_dist[i] = element_dist(clusters[i])\n",
    "    s = 0\n",
    "    for i in range(n):\n",
    "        mx = 0\n",
    "        for j in range(i+1, n):\n",
    "            fact = (average_element_dist[i]+average_element_dist[j])/clusters_dist(clusters, i, j)\n",
    "            mx = max(mx, fact)\n",
    "        s += mx\n",
    "    return s/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### indeks Dunna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DI(clusters):\n",
    "    n = len(clusters)\n",
    "    mn = 1000000 # min odległość pomiędzy klastrami\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            mn = min(mn, clusters_dist(clusters, i, j))\n",
    "            \n",
    "    mx = 0   # max odległość między elementami w klastrze -> przyjmuję tu max średnią odległość \n",
    "             # pomiędzy elementami w klastrze\n",
    "        \n",
    "    average_element_dist = [0]*n\n",
    "    for i in range(n):\n",
    "        average_element_dist[i] = element_dist(clusters[i])\n",
    "    mx = max(average_element_dist)\n",
    "    \n",
    "    return mn/mx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stoplista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_stoplist():\n",
    "    file = open('lines_short.txt')\n",
    "    text1 = file.read()\n",
    "    text1 = text1.split(\" \")\n",
    "    file.close()\n",
    "\n",
    "    d = {}\n",
    "    for word in text1:\n",
    "        if word in d.keys():\n",
    "            d[word]+=1\n",
    "        else:\n",
    "            d[word] = 1\n",
    "        \n",
    "    return dict(sorted(d.items(), key=lambda item: -item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_words(n): # n - liczba słów do usunięcia\n",
    "    \n",
    "    d = get_sorted_stoplist()\n",
    "    to_delete = set()\n",
    "    j = 0\n",
    "    for i in d.keys():\n",
    "        to_delete.add(i)\n",
    "        j +=1\n",
    "        if j > n:\n",
    "            break\n",
    "    \n",
    "    file = open('lines_short.txt')\n",
    "    text1 = file.read()\n",
    "    text1 = text1.split(\"\\n\")\n",
    "    file.close()\n",
    "    \n",
    "    lines_n = len(text1)\n",
    "    new_text = [None]*lines_n\n",
    "    i = 0\n",
    "    for line in text1:\n",
    "        lin = line.split(\" \")\n",
    "        for j in range(len(lin)):\n",
    "            word = lin[j]\n",
    "            if word in to_delete:\n",
    "                lin[j] = ''\n",
    "        lin = ''.join(lin)\n",
    "        new_text[i] = lin\n",
    "        i +=1\n",
    "        \n",
    "    return new_text\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klasteryzacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('lines_short.txt')\n",
    "text = file.read()\n",
    "text = text.split('\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_s = delete_words(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_X(text):\n",
    "    d = {}\n",
    "    for line in text:\n",
    "        d = n_gram_dict(line, 4, d)\n",
    "\n",
    "    i = 0    \n",
    "    for key in d.keys():\n",
    "        d[key] = i\n",
    "        i +=1\n",
    "    n = len(text)-1\n",
    "    keys_num = len(d.keys())\n",
    "    \n",
    "    X = np.zeros((n, keys_num))\n",
    "    i = 0\n",
    "\n",
    "    for line in text:\n",
    "        if len(line)<=2:\n",
    "            break\n",
    "        line_d = n_gram_dict(line, 4, {})\n",
    "    \n",
    "        for key in line_d.keys():\n",
    "            X[i][d[key]] = line_d[key]\n",
    "        i +=1\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labels(X, labels):\n",
    "    i = 1\n",
    "    while labels[-i] == -1:\n",
    "        i+=1\n",
    "    n = labels[-i]\n",
    "    clusters = [None]*(n+1)\n",
    "    for i in range(len(clusters)):\n",
    "        clusters[i] = []\n",
    "    for i in range(len(labels)):\n",
    "        clusters[labels[i]].append(X[i])\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = prepare_X(text)\n",
    "X_s = prepare_X(text_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klasteryzacja z metryką euklidesową\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bez stoplisty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  2  3  4  5  6  7  8  9 10 11 11 11 11 11 11 11 12 12 13 14 15\n",
      " 16 17 18 19 19 20 21 22 23 24]\n",
      "0.3304436663402599\n",
      "1.1981825350018183\n"
     ]
    }
   ],
   "source": [
    "clustering = DBSCAN(eps=7, min_samples=1, metric = euclidean_metric).fit(X)\n",
    "labels = clustering.labels_\n",
    "print(labels)\n",
    "clusters = convert_labels(X,labels)\n",
    "print(DBI(clusters))\n",
    "print(DI(clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Po usunięciu wyrazów ze stoplisty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  2  3  4  5  6  7  8  9 10 11 11 11 11 11 11 11 12 12 13 14 15\n",
      " 16 17 18 19 19 20 21 22 23 24]\n",
      "0.23383988909126718\n",
      "1.2360330811826106\n"
     ]
    }
   ],
   "source": [
    "clustering = DBSCAN(eps=7, min_samples=1, metric = euclidean_metric).fit(X_s)\n",
    "labels = clustering.labels_\n",
    "print(labels)\n",
    "clusters = convert_labels(X_s,labels)\n",
    "print(DBI(clusters))\n",
    "print(DI(clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klasteryzacja z metryką cosinusową"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bez stoplisty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  2  3  4  5  6  7  8  9 10 11 11 11 11 11 11 11 12 12 13 14 15\n",
      " 16 17 18 19 19 20 21 22 23 -1]\n",
      "0.7884933101294617\n",
      "0.9830496196132974\n"
     ]
    }
   ],
   "source": [
    "clustering = DBSCAN(eps=0.3, min_samples=1, metric = cosine_metric).fit(X)\n",
    "labels = clustering.labels_\n",
    "print(labels)\n",
    "clusters = convert_labels(X,labels)\n",
    "print(DBI(clusters))\n",
    "print(DI(clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Po usunięciu wyrazów ze stoplisty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  2  3  4  5  6  7  8  9 10 11 11 11 11 11 11 11 12 12 13 14 15\n",
      " 16 17 18 19 19 20 21 22 23 -1]\n",
      "0.7404031264825819\n",
      "1.0488088481701516\n"
     ]
    }
   ],
   "source": [
    "clustering = DBSCAN(eps=0.3, min_samples=1, metric = cosine_metric).fit(X_s)\n",
    "labels = clustering.labels_\n",
    "print(labels)\n",
    "clusters = convert_labels(X_s,labels)\n",
    "print(DBI(clusters))\n",
    "print(DI(clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klasteryzacja z metryką Dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bez stoplisty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  2  3  4  5  6  7  8  9 10 11 11 11 11 11 11 11 12 12 13 14 15\n",
      " 16 17 18 19 19 20 21 22 23 24]\n",
      "0.3304436663402599\n",
      "1.1981825350018183\n"
     ]
    }
   ],
   "source": [
    "clustering = DBSCAN(eps=0.3, min_samples=1, metric = dice_metric).fit(X)\n",
    "labels = clustering.labels_\n",
    "print(labels)\n",
    "clusters = convert_labels(X,labels)\n",
    "print(DBI(clusters))\n",
    "print(DI(clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Po usunięciu wyrazów ze stoplisty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  2  3  4  5  6  7  8  9 10 11 11 11 11 11 11 11 12 12 13 14 15\n",
      " 16 17 18 19 19 20 21 22 23 24]\n",
      "0.23383988909126718\n",
      "1.2360330811826106\n"
     ]
    }
   ],
   "source": [
    "clustering = DBSCAN(eps=0.3, min_samples=1, metric = dice_metric).fit(X_s)\n",
    "labels = clustering.labels_\n",
    "print(labels)\n",
    "clusters = convert_labels(X_s,labels)\n",
    "print(DBI(clusters))\n",
    "print(DI(clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klasteryzacja z odległością Levensteina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bez stoplisty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  2  3  4  5  6  7  8  9 10 11 11 11 11 11 11 11 12 12 13 14 15\n",
      " 16 17 18 19 19 20 21 22 23 24]\n",
      "0.3304436663402599\n",
      "1.1981825350018183\n"
     ]
    }
   ],
   "source": [
    "matrix = Levenshtein_matrix_dist(text)\n",
    "clustering = DBSCAN(eps=7, min_samples=1).fit(X, matrix)\n",
    "labels = clustering.labels_\n",
    "print(labels)\n",
    "clusters = convert_labels(X,labels)\n",
    "print(DBI(clusters))\n",
    "print(DI(clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Po usunięciu wyrazów ze stoplisty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  2  3  4  5  6  7  8  9 10 11 11 11 11 11 11 11 12 12 13 14 15\n",
      " 16 17 18 19 19 20 21 22 23 24]\n",
      "0.23383988909126718\n",
      "1.2360330811826106\n"
     ]
    }
   ],
   "source": [
    "matrix = Levenshtein_matrix_dist(text_s)\n",
    "clustering = DBSCAN(eps=7, min_samples=1).fit(X_s, matrix)\n",
    "labels = clustering.labels_\n",
    "print(labels)\n",
    "clusters = convert_labels(X_s,labels)\n",
    "print(DBI(clusters))\n",
    "print(DI(clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klasteryzacja z metryką LCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bez stoplisty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  2  3  4  5  6  7  8  9 10 11 11 11 11 11 11 11 12 12 13 14 15\n",
      " 16 17 18 19 19 20 21 22 23 24]\n",
      "0.3304436663402599\n",
      "1.1981825350018183\n"
     ]
    }
   ],
   "source": [
    "matrix = LCS_matrix(text)\n",
    "clustering = DBSCAN(eps=7, min_samples=1).fit(X, matrix)\n",
    "labels = clustering.labels_\n",
    "print(labels)\n",
    "clusters = convert_labels(X,labels)\n",
    "print(DBI(clusters))\n",
    "print(DI(clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Po usunięciu wyrazów ze stoplisty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  2  3  4  5  6  7  8  9 10 11 11 11 11 11 11 11 12 12 13 14 15\n",
      " 16 17 18 19 19 20 21 22 23 24]\n",
      "0.23383988909126718\n",
      "1.2360330811826106\n"
     ]
    }
   ],
   "source": [
    "matrix = LCS_matrix(text_s)\n",
    "clustering = DBSCAN(eps=7, min_samples=1).fit(X_s, matrix)\n",
    "labels = clustering.labels_\n",
    "print(labels)\n",
    "clusters = convert_labels(X_s,labels)\n",
    "print(DBI(clusters))\n",
    "print(DI(clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podsumowanie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obliczenia zostały wykonane dla bardzo skróconego pliku, ponieważ zajmowały bardzo dużo czasu, a klasteryzację należało wykonać 10 razy. Z tego względu usunięto tylko 10 pierwszych słów ze stoplisty - najczęściej występujących słów w tekście. Dla tak małej liczby linijek w prawie każdym przypadku klasteryzacja daje poprawny wynik, zostało to osiągnięte dzięki kilkukrotnemu sprawdzaniu najlepszej wartości hiperparametru epsilon dla każdej metryki. Po usunięciu wyrazów ze stoplisty wartość współczynnika DB znacznie się zmniejszyła (o ok. 50%), nastomiast współczynnik Dunna się nieznacznie zwiększył.\n",
    "Aby poprawić jakość klasteryzacji należałoby wykonać kolejne obliczenia zmieniając np. rozmiar n-gramów (w aktualnej wersji rozważam 4-gramy) sprawdzając jaki rozmiar daje najlepsze rozwiązanie."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
